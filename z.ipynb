{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution with exact Newton's step: [ 0.59296547  0.45855148  0.02687405  0.44679509  0.71903654  0.53673013\n",
      "  0.50722827  0.4857465   0.28490419  0.13449919  0.66983319  0.68746915\n",
      "  0.78546971  0.69645867  0.62537435  0.33661067  0.15099516 -0.15359892\n",
      " -0.0342159   0.01870965  0.0165668   0.73699825  1.08483914  1.09930598\n",
      "  0.90953726  0.59332463  0.06209645 -0.40143229  0.50022293  0.47323492\n",
      "  0.56574605  0.59743966  0.66307704  0.20055644  0.0508991  -0.02942428\n",
      "  0.00838037 -0.11728376 -0.44471777  0.39436722  0.38670813  0.50235004\n",
      "  0.44969146 -0.03280621  0.43542671  0.73344676  0.72178562  0.69541317\n",
      "  0.5918374   0.40511501  0.22620757 -0.01207019  0.67625627  0.57323953\n",
      "  0.54795996  0.50150506  0.35162112  0.24416848  0.34099208  0.16437595\n",
      "  0.60075508  0.83112121  0.83630243  0.74035141  0.66097912  0.46349946\n",
      "  0.5570748   0.26304678  0.23023656  0.40860016  0.49919843  0.60309163\n",
      "  0.51863789  0.37089682  0.22844674 -0.06298117  0.04769188 -0.66159085\n",
      "  0.04740107 -0.16207707  0.28061577  0.41007807  0.50131022  0.28103891\n",
      "  0.41565341  0.55423256  0.34685206  0.13498878  0.18998575  0.54446717\n",
      "  0.29895735  0.43240924  0.51011537  0.38921714  0.52033497  0.5634048\n",
      "  0.43010796  0.40802437  0.45701947  0.11508529]\n",
      "Execution time (exact): 0.08697819709777832\n",
      "Solution with approximate Newton's step: [0.61773795 0.80473086 0.37936902 0.72370455 0.99322222 0.43389133\n",
      " 0.64360027 0.79708366 0.54528352 0.20300423 0.85489242 0.58381033\n",
      " 0.89514456 0.76189059 0.87409165 0.61215795 0.55221394 0.10054346\n",
      " 0.13392141 0.18789471 0.17419155 0.31464905 0.3912228  0.2716252\n",
      " 0.53542563 0.02479529 0.28219506 0.61120979 0.91669128 0.32647924\n",
      " 0.68946385 0.58424423 0.92814311 0.05058945 0.23573892 0.09898437\n",
      " 0.31523443 0.23405576 0.07461833 0.67483162 0.23073067 0.13930995\n",
      " 0.78117385 0.08278282 0.28385346 0.77874934 0.35831282 0.40011623\n",
      " 0.50067193 0.40997081 0.39476387 0.03000988 0.8773759  0.3305548\n",
      " 0.20615334 0.73739267 0.65924627 0.76014737 0.78151965 0.24821173\n",
      " 0.28550816 0.87853659 0.70629572 0.20665519 0.00998259 0.54909057\n",
      " 0.85634923 0.26890158 0.02277626 0.37812201 0.18888008 0.6152247\n",
      " 0.23597708 0.71237906 0.74631603 0.49194793 0.73052571 0.04321604\n",
      " 0.52989197 0.32175525 0.51981315 0.29990208 0.8166945  0.45145704\n",
      " 0.54533504 0.98600845 0.72765376 0.3527221  0.0591205  0.82845826\n",
      " 0.22700768 0.68975877 0.81368681 0.52425497 0.72018436 0.69844572\n",
      " 0.21549343 0.19117272 0.90331716 0.67791118]\n",
      "Execution time (approximate): 11.458649158477783\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Objective function: Rosenbrock function\n",
    "def rosenbrock(x):\n",
    "    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)\n",
    "\n",
    "# Exact gradient of the Rosenbrock function\n",
    "def rosenbrock_gradient(x):\n",
    "    xm = x[1:-1]\n",
    "    xm_m1 = x[:-2]\n",
    "    xm_p1 = x[2:]\n",
    "    der = np.zeros_like(x)\n",
    "    der[1:-1] = 200*(xm-xm_m1**2) - 400*(xm_p1 - xm**2)*xm - 2*(1-xm)\n",
    "    der[0] = -400*x[0]*(x[1]-x[0]**2) - 2*(1-x[0])\n",
    "    der[-1] = 200*(x[-1]-x[-2]**2)\n",
    "    return der\n",
    "\n",
    "# Exact Hessian of the Rosenbrock function\n",
    "def rosenbrock_hessian(x):\n",
    "    x = np.asarray(x)\n",
    "    H = np.diag(-400*x[:-1],1) - np.diag(400*x[:-1],-1)\n",
    "    diagonal = np.zeros_like(x)\n",
    "    diagonal[0] = 1200*x[0]**2-400*x[1]+2\n",
    "    diagonal[-1] = 200\n",
    "    diagonal[1:-1] = 202 + 1200*x[1:-1]**2 - 400*x[2:]\n",
    "    H = H + np.diag(diagonal)\n",
    "    return H\n",
    "\n",
    "# Approximate gradient using finite differences\n",
    "def approximate_gradient(x, eps=1e-5):\n",
    "    grad = np.zeros_like(x)\n",
    "    for i in range(len(x)):\n",
    "        x1 = x.copy()\n",
    "        x2 = x.copy()\n",
    "        x1[i] += eps\n",
    "        x2[i] -= eps\n",
    "        grad[i] = (rosenbrock(x1) - rosenbrock(x2)) / (2*eps)\n",
    "    return grad\n",
    "\n",
    "# Approximate Hessian using finite differences\n",
    "def approximate_hessian(x, eps=1e-5):\n",
    "    n = len(x)\n",
    "    hessian = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            x1 = x.copy()\n",
    "            x2 = x.copy()\n",
    "            x1[i] += eps\n",
    "            x1[j] += eps\n",
    "            x2[i] -= eps\n",
    "            x2[j] -= eps\n",
    "            hessian[i,j] = (rosenbrock(x1) - rosenbrock(x2)) / (4*eps**2)\n",
    "    return hessian\n",
    "\n",
    "# Line search: Golden Section Search\n",
    "def golden_section_search(f, x, dx, a, b, tol=1e-5):\n",
    "    phi = (np.sqrt(5) - 1) / 2\n",
    "    c = b - phi * (b - a)\n",
    "    d = a + phi * (b - a)\n",
    "    while abs(c - d) > tol:\n",
    "        if f(x + c*dx) < f(x + d*dx):\n",
    "            b = d\n",
    "        else:\n",
    "            a = c\n",
    "        c = b - phi * (b - a)\n",
    "        d = a + phi * (b - a)\n",
    "    return (b + a) / 2\n",
    "\n",
    "def newton_optimization(initial_point, max_iter=50, line_search=True, approximate=False):\n",
    "    xk = initial_point.copy()\n",
    "    n = len(xk)\n",
    "    for k in range(max_iter):\n",
    "        if approximate:\n",
    "            gk = approximate_gradient(xk)\n",
    "            Hk = approximate_hessian(xk)\n",
    "        else:\n",
    "            gk = rosenbrock_gradient(xk)\n",
    "            Hk = rosenbrock_hessian(xk)\n",
    "\n",
    "        dxk = np.linalg.solve(Hk, -gk)  # Newton's direction\n",
    "        \n",
    "        if line_search:\n",
    "            alpha = golden_section_search(rosenbrock, xk, dxk, 0, 1)\n",
    "        else:\n",
    "            alpha = 1  # Exact Newton's step\n",
    "\n",
    "        xk = xk + alpha * dxk  # Update current point\n",
    "\n",
    "    return xk\n",
    "\n",
    "# Test the optimization\n",
    "n = 100\n",
    "initial_point = np.random.rand(n)\n",
    "\n",
    "start_time = time.time()\n",
    "x_min_exact = newton_optimization(initial_point, line_search=True, approximate=False)\n",
    "end_time = time.time()\n",
    "exact_time = end_time - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "x_min_approx = newton_optimization(initial_point, line_search=True, approximate=True)\n",
    "end_time = time.time()\n",
    "approx_time = end_time - start_time\n",
    "\n",
    "print(\"Solution with exact Newton's step:\", x_min_exact)\n",
    "print(\"Execution time (exact):\", exact_time)\n",
    "\n",
    "print(\"Solution with approximate Newton's step:\", x_min_approx)\n",
    "print(\"Execution time (approximate):\", approx_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
